# LLM APIå®¢æˆ·ç«¯
"""
LLMå®¢æˆ·ç«¯æ¨¡å—
=============
ç»Ÿä¸€å°è£…AIæ¨¡åž‹è°ƒç”¨ï¼Œå…¨è¯¾ç¨‹å¤ç”¨
æ”¯æŒDeepSeekã€GPTã€Claudeç­‰ï¼ˆéƒ½å…¼å®¹OpenAIæ ¼å¼ï¼‰
"""

import os
import json
from openai import OpenAI


class DeepSeekClient:
    """
    DeepSeek API å®¢æˆ·ç«¯

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ðŸ“– æœ¯è¯­ï¼šClientï¼ˆå®¢æˆ·ç«¯ï¼‰                     â”‚
    â”‚    å°±æ˜¯"å¸®ä½ æ‰“ç”µè¯ç»™AIæœåŠ¡å™¨çš„å·¥å…·"ã€‚           â”‚
    â”‚    ä½ å‘Šè¯‰Clientè¦é—®ä»€ä¹ˆï¼ŒClientå¸®ä½ å‘è¯·æ±‚ã€     â”‚
    â”‚    æ”¶å›žç­”ã€å¤„ç†é”™è¯¯ã€‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ä½¿ç”¨æ–¹å¼ï¼š
        from quant_core.ai import DeepSeekClient
        client = DeepSeekClient()
        answer = client.chat("åˆ†æžè´µå·žèŒ…å°çš„æŠ•èµ„ä»·å€¼")
    """

    # æ¨¡åž‹é…ç½®
    MODELS = {
        "v3":   "deepseek-chat",        # DeepSeek-V3.2: éžæ€è€ƒæ¨¡å¼
        "r1":   "deepseek-reasoner",    # DeepSeek-V3.2: æ€è€ƒæ¨¡å¼
    }

    def __init__(self, api_key: str = None, model: str = "v3"):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯

        å‚æ•°ï¼š
            api_key: DeepSeek API Keyã€‚
                     å¦‚æžœä¸ä¼ ï¼Œä¼šè‡ªåŠ¨ä»ŽçŽ¯å¢ƒå˜é‡ DEEPSEEK_API_KEY è¯»å–
            model:   "v3" = DeepSeek-V3ï¼ˆä¾¿å®œå¿«é€Ÿï¼‰
                     "r1" = DeepSeek-R1ï¼ˆå¼ºæŽ¨ç†ï¼‰
        """
        self.api_key = api_key
        if not self.api_key:
            try:
                from config import settings as _settings

                self.api_key = getattr(_settings, "DEEPSEEK_API_KEY", "") or self.api_key
            except Exception:
                pass
        if not self.api_key:
            self.api_key = os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError(
                "âŒ æœªæ‰¾åˆ°API Keyï¼è¯·è®¾ç½®çŽ¯å¢ƒå˜é‡ï¼š\n"
                "   export DEEPSEEK_API_KEY='ä½ çš„key'  (Mac/Linux)\n"
                "   set DEEPSEEK_API_KEY=ä½ çš„key        (Windows)\n"
                "   æˆ–è€…ç›´æŽ¥ä¼ å…¥ï¼šDeepSeekClient(api_key='ä½ çš„key')"
            )

        self.model_name = self.MODELS.get(model, model)

        # åˆ›å»ºOpenAIå…¼å®¹å®¢æˆ·ç«¯
        # DeepSeekçš„APIæ ¼å¼å’ŒOpenAIå®Œå…¨ä¸€è‡´ï¼Œåªæ˜¯base_urlä¸åŒ
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com",  # DeepSeekçš„æœåŠ¡å™¨åœ°å€
        )

        self._system_prompt = None  # ç³»ç»Ÿæç¤ºè¯

    def set_system_prompt(self, prompt: str):
        """
        è®¾ç½®ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ðŸ“– System Prompt = AIçš„"å²—ä½è¯´æ˜Žä¹¦"       â”‚
        â”‚    è®¾å®šAIçš„è§’è‰²ã€èƒ½åŠ›èŒƒå›´ã€å›žç­”è§„èŒƒã€‚       â”‚
        â”‚    æ‰€æœ‰åŽç»­å¯¹è¯éƒ½ä¼šå—å®ƒå½±å“ã€‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        self._system_prompt = prompt
        return self  # æ”¯æŒé“¾å¼è°ƒç”¨

    def chat(
        self,
        message: str,
        temperature: float = 0.1,
        max_tokens: int = 4096,
        json_output: bool = False,
    ) -> str:
        """
        å‘é€æ¶ˆæ¯ç»™AIï¼ŒèŽ·å–å›žç­”

        å‚æ•°ï¼š
            message:     ä½ çš„é—®é¢˜/æŒ‡ä»¤
            temperature: éšæœºåº¦ï¼ˆ0=ç¡®å®š, 1=æœ‰åˆ›æ„ï¼‰é‡åŒ–åˆ†æžå»ºè®®0~0.3
            max_tokens:  å›žç­”çš„æœ€å¤§é•¿åº¦ï¼ˆTokenæ•°ï¼‰
            json_output: æ˜¯å¦å¼ºåˆ¶JSONæ ¼å¼è¾“å‡º

        è¿”å›žï¼š
            AIçš„å›žç­”æ–‡æœ¬
        """
        # æž„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        if self._system_prompt:
            messages.append({"role": "system", "content": self._system_prompt})
        messages.append({"role": "user", "content": message})

        # æž„å»ºè¯·æ±‚å‚æ•°
        kwargs = {
            "model": self.model_name,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }

        # å¦‚æžœè¦æ±‚JSONè¾“å‡º
        if json_output:
            kwargs["response_format"] = {"type": "json_object"}

        # è°ƒç”¨API
        response = self.client.chat.completions.create(**kwargs)

        # æå–å›žç­”æ–‡æœ¬
        return response.choices[0].message.content

    def chat_json(self, message: str, temperature: float = 0.0) -> dict:
        """
        å‘é€æ¶ˆæ¯å¹¶èŽ·å–JSONæ ¼å¼çš„å›žç­”ï¼ˆè‡ªåŠ¨è§£æžä¸ºå­—å…¸ï¼‰

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ðŸ“– ä¸ºä»€ä¹ˆéœ€è¦JSONè¾“å‡ºï¼Ÿ                       â”‚
        â”‚    é‡åŒ–ç³»ç»Ÿéœ€è¦ç¨‹åºè‡ªåŠ¨å¤„ç†AIçš„å›žç­”ã€‚           â”‚
        â”‚    è‡ªç”±æ–‡æœ¬å¾ˆéš¾è§£æžï¼ŒJSONå¯ä»¥ç›´æŽ¥å˜æˆå­—å…¸ï¼š     â”‚
        â”‚    {"signal": "BUY", "confidence": 0.8}     â”‚
        â”‚    ç¨‹åºå°±èƒ½è¯»å– result["signal"] == "BUY"    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
        text = self.chat(message, temperature=temperature, json_output=True)

        # å°è¯•è§£æžJSON
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            # æœ‰æ—¶AIè¿”å›žçš„JSONå¤–é¢åŒ…äº†```json ...```ï¼Œéœ€è¦æ¸…ç†
            cleaned = text.strip()
            if cleaned.startswith("```"):
                cleaned = cleaned.split("\n", 1)[1]  # åŽ»æŽ‰ç¬¬ä¸€è¡Œ
                cleaned = cleaned.rsplit("```", 1)[0]  # åŽ»æŽ‰æœ€åŽçš„```
            return json.loads(cleaned)

    def estimate_cost(
        self,
        input_text: str,
        output_tokens: int = 1000,
        cache_hit: bool = False,
    ) -> dict:
        """
        ä¼°ç®—æœ¬æ¬¡è°ƒç”¨çš„è´¹ç”¨

        è¿”å›žï¼š
            {"input_tokens": ..., "output_tokens": ...,
             "estimated_cost_rmb": ...}
        """
        # ç²—ç•¥ä¼°ç®—ï¼š1è‹±æ–‡å­—ç¬¦â‰ˆ0.3tokenï¼Œ1ä¸­æ–‡å­—ç¬¦â‰ˆ0.6token
        input_tokens = 0.0
        for ch in input_text:
            if ord(ch) < 128:
                input_tokens += 0.3
            else:
                input_tokens += 0.6
        input_tokens = int(input_tokens)

        # DeepSeek-V3.2 å®šä»·ï¼ˆè¾“å…¥åŒºåˆ†ç¼“å­˜å‘½ä¸­/æœªå‘½ä¸­ï¼‰
        if cache_hit:
            input_price = 0.2 / 1_000_000   # Â¥0.2/1M tokens
        else:
            input_price = 2.0 / 1_000_000   # Â¥2/1M tokens
        output_price = 3.0 / 1_000_000      # Â¥3/1M tokens

        cost = input_tokens * input_price + output_tokens * output_price

        return {
            "input_tokensï¼ˆè¾“å…¥è¯å…ƒæ•°ï¼‰": input_tokens,
            "output_tokensï¼ˆè¾“å‡ºè¯å…ƒæ•°ï¼‰": output_tokens,
            "estimated_cost_rmbï¼ˆé¢„ä¼°è´¹ç”¨/å…ƒï¼‰": round(cost, 6),
        }